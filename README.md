
This repository demonstrates how to build a chatbot named SuperBot using LangGraph and LLMs (Large Language Models) like OpenAI GPT or Groq.

Key concepts covered:

	â€¢	Using graph structures to design chatbot workflows.

	â€¢	Managing conversation history with reducers (add_messages).

	â€¢	Connecting to OpenAI GPT or Groq models.

	â€¢	Running and streaming chatbot responses.

    By the end, you will have a working chatbot capable of handling back-and-forth conversations while maintaining memory of past interactions.

â¸»

ğŸ› ï¸ Setup & Installation

	1.	Create and activate a virtual environment:

        python -m venv venv
        

	2.	Install dependencies:

         pip install -r requirements.txt


	3.	Create a .env file in the project root with your API keys:

        OPENAI_API_KEY=your_openai_api_key
        GROQ_API_KEY=your_groq_api_key


â¸»

ğŸ“š Concepts

    1. Graph Structure

        The chatbot is represented as a graph:

    Start â†’ SuperBot Node â†’ End

        â€¢	Start: Entry point.
        â€¢	SuperBot Node: Where the LLM is invoked.
        â€¢	End: Conversation completion.

    2. Reducers (add_messages)

        Reducers are used to maintain conversation history.
            â€¢	add_messages appends each new user/AI message instead of overwriting.
            â€¢	This allows the chatbot to remember past interactions.

    3. State Class

     The chatbotâ€™s memory is defined using TypedDict.

        â€¢	messages stores the full conversation as a list.
        â€¢	Each new message (user or AI) gets appended.

    4. LLMs Used
        â€¢	OpenAI GPT Models â†’ via ChatOpenAI (paid).
        â€¢	Groq Models â†’ via ChatGroq (some free).

    Both can be invoked with a simple call:

    model.invoke("Hello")


â¸»

ğŸš€ Building the Chatbot

	1.	Define State

                Store conversation messages in the state.

	2.	Load Environment Variables

                Securely load API keys from .env.

	3.	Set up LLM Models

                Connect to GPT or Groq.

	4.	Define SuperBot Function

                Handles message processing by calling the LLM.

	5.	Build Graph

                Add nodes and edges

	6.	Compile Graph

â¸»

â–¶ï¸ Execution

    Direct Invocation

    Run the chatbot with one input:

    result.invoke({"messages": "Hi, my name is Karthik and I am an AI Engineer"})

    Streaming Responses

    â¸»

ğŸ“Š Visualizing the Graph

    You can generate a graph visualization of the chatbot pipeline

â¸»

âœ… Key Takeaways

	â€¢	LangGraph provides a graph-based approach for building AI apps.

	â€¢	Reducers like add_messages help maintain conversation memory.

	â€¢	LLMs such as GPT or Groq can be easily integrated.

	â€¢	Supports both direct execution and streaming responses.
    
	â€¢	The chatbot is modular, making it easy to expand with more nodes.

â¸»

ğŸ“‚ Repository Structure

    â”œâ”€â”€ superbot.ipynb       # Notebook version with examples
    â”œâ”€â”€ superbot.py          # Python program file
    â”œâ”€â”€ requirements.txt     # Dependencies
    â”œâ”€â”€ README.md            # Documentation


â¸»

ğŸ¯ Conclusion

    SuperBot demonstrates the power of combining LangGraph with LLMs to create flexible, memory-enabled chatbots. The modular graph-based design makes it easy to scale, customize, and deploy in real-world applications.
